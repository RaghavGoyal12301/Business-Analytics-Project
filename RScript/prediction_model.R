source("RScript/load_libraries.R")

# ------------------------------Reading Prepared Data------------------------------
data <- read.csv("Data/diabetes_data_new.csv")
data <- data[, - c(1)] # Removing annonymous column generated by write.csv() for mapping observations

for (col in 1:ncol(data)) {
  if (is.numeric(data[, col])) {
    data[, col] <- as.numeric(data[, col])
  } else {
    data[, col] <- as.factor(data[, col])
  }
}



# ------------------------------Dividing Data for Training & Testing------------------------------
# Split the Dataset into Training Data and Test Data.
# Use set.seed(100) as a seed and split the dataset into training and test set with 80:20 proportion, respectively.
set.seed(123)
id <- sample(2, nrow(data), replace = T, prob = c(0.8, 0.2))
data_train <- data[id == 1,]
data_test <- data[id == 2,]



# ------------------------------Data Balancing------------------------------
data_train <- ROSE(readmitted ~ ., data = data_train)$data




# ------------------------------Training Model------------------------------
data_train$readmitted <- as.factor(data_train$readmitted)
data_test$readmitted <- as.factor(data_test$readmitted)

rf_model <- randomForest(readmitted ~ ., data = data_train, mtry=12, ntree = 400) #<------Can be Configured for more accuracy

prd1 <- predict(rf_model, data_train)
prd2 <- predict(rf_model, data_test)

plot(rf_model) # Error rate of Random Forest

confusionMatrix(prd1, data_train$readmitted)
confusionMatrix(prd2, data_test$readmitted)

varImpPlot(rf_model)
importance(rf_model)
varUsed(rf_model)

# t <- tuneRF(data_train[, -41], data_train[, 41],
#             stepFactor = 0.5,
#             plot = TRUE,
#             ntreeTry = 400,
#             trace = TRUE,
#             improve = 0.05
#             )